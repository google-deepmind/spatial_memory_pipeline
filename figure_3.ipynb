{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "532jUiWVFvuK"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 DeepMind Technologies Limited\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amXwOIJTov3g"
      },
      "outputs": [],
      "source": [
        "# Download code to import locally.\n",
        "# The '/content' path is meant for cloud-based Google Colab.\n",
        "# If running on a local Colab, you may want to change that to a different\n",
        "# local path.\n",
        "import os\n",
        "import requests\n",
        "import shutil\n",
        "\n",
        "path = \"/content\"\n",
        "github_path = \"https://raw.githubusercontent.com/deepmind/spatial_memory_pipeline/master/src/\"\n",
        "local_folder = \"spatial_memory_pipeline\"\n",
        "filenames = [\"dataset.py\", \"plot_utils.py\"]\n",
        "\n",
        "!cd {path}\n",
        "!mkdir {path}/{local_folder}\n",
        "!touch {path}/{local_folder}/__init__.py\n",
        "\n",
        "for name in filenames:\n",
        "  source = os.path.join(github_path, name)\n",
        "  dest = os.path.join(path, local_folder, name)\n",
        "  with requests.get(source, stream=True) as r, open(dest, 'wb') as w:\n",
        "    r.raise_for_status()\n",
        "    for chunk in r.iter_content(chunk_size=128):\n",
        "        w.write(chunk)\n",
        "    w.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys7gTj2q_7uq"
      },
      "outputs": [],
      "source": [
        "# Imports.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.cm import get_cmap\n",
        "from matplotlib.offsetbox import OffsetImage\n",
        "from matplotlib.offsetbox import AnnotationBbox\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "\n",
        "from spatial_memory_pipeline import dataset\n",
        "from spatial_memory_pipeline import plot_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehlDcLY2D_6J"
      },
      "outputs": [],
      "source": [
        "# Functions to unroll the model RNNs.\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1. / (1.+np.exp(-x))\n",
        "\n",
        "\n",
        "def softmax(x, axis=-1):\n",
        "  \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "  e_x = np.exp(x - np.amax(x, axis=axis, keepdims=True))\n",
        "  return e_x / e_x.sum(axis=axis, keepdims=True)\n",
        "\n",
        "\n",
        "def step_of_lstm(state, inputs, w, b):\n",
        "  forget_bias = 1\n",
        "  prev_hidden, prev_cell = state\n",
        "  inputs_and_hidden = np.concatenate([inputs, prev_hidden], axis=-1)\n",
        "  gates = np.matmul(inputs_and_hidden, w) + b\n",
        "\n",
        "  # i = input_gate, j = next_input, f = forget_gate, o = output_gate\n",
        "  i, j, f, o = np.split(gates, 4, axis=-1)\n",
        "\n",
        "  forget_mask = sigmoid(f + forget_bias)\n",
        "  next_cell = forget_mask * prev_cell + sigmoid(i) * np.tanh(j)\n",
        "  cell_output = next_cell\n",
        "  next_hidden = sigmoid(cell_output) * sigmoid(o)\n",
        "\n",
        "  return next_hidden, (next_hidden, next_cell)\n",
        "\n",
        "\n",
        "def get_visual_correction_codes(parameters, visual_embeddings):\n",
        "  \"\"\"Calculates visual correction codes for a set of visual embeddings.\"\"\"\n",
        "  # hd_embeddings corresponds to m^{(x)} in methods\n",
        "  hd_embeddings = parameters[\"integrator/memory_map_0/column_context_3\"]\n",
        "  # memory_of_visual_embeddings corresponds to m^{(y)} in methods\n",
        "  memory_of_visual_embeddings = parameters[\"integrator/memory_map_0/column_context_2\"]\n",
        "  # gamma is the correction inverse temperature\n",
        "  gamma = np.exp(parameters[\"integrator/multi_integrator_nets/mmap_0_context_2_query_beta\"])\n",
        "  w_s = softmax(gamma * np.matmul(visual_embeddings, memory_of_visual_embeddings.T),\n",
        "                axis=-1)\n",
        "  correction_codes = np.matmul(w_s, hd_embeddings)\n",
        "  return correction_codes\n",
        "\n",
        "\n",
        "def unroll_rnn_with_fixed_vel(initial_state, ang_vel, n_steps, rnn_step_func):\n",
        "  \"\"\"Unroll one rnn with a constant velocity input.\"\"\"\n",
        "  B = initial_state.shape[0]\n",
        "  vel_inputs = np.tile(np.asarray([[np.cos(ang_vel), np.sin(ang_vel)]]),\n",
        "                       (B, 1))\n",
        "  # Velocities are scaled to increase range\n",
        "  vel_inputs *= 10\n",
        "  state_traj = list()\n",
        "  state_traj.append(initial_state)\n",
        "  rnn_state = (initial_state, initial_state)\n",
        "  for t in range(n_steps):\n",
        "    output, rnn_state = rnn_step_func(rnn_state, vel_inputs)\n",
        "    state_traj.append(output)\n",
        "  return np.asarray(state_traj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht0iwXu0X7x4"
      },
      "outputs": [],
      "source": [
        "# Auxiliary functions.\n",
        "\n",
        "def take_if_farther_than(points, distance_f, threshold):\n",
        "  \"\"\"Filters points choosing a subset such that they are all at least\n",
        "  `threshold` distance from each other.\n",
        "\n",
        "  Returns a tuple with the indices of the filtered points, and their values.\n",
        "  \"\"\"\n",
        "  chosen_points = list()\n",
        "  chosen_indices = list()\n",
        "  for i, p in enumerate(points):\n",
        "    if i == 0:\n",
        "      chosen_points.append(p)\n",
        "      chosen_indices.append(i)\n",
        "    else:\n",
        "      min_d = np.inf\n",
        "      for ch in chosen_points:\n",
        "        if distance_f(p, ch) \u003c min_d:\n",
        "          min_d = distance_f(p, ch)\n",
        "      if min_d \u003e threshold:\n",
        "        chosen_points.append(p)\n",
        "        chosen_indices.append(i)\n",
        "  return chosen_indices, np.asarray(chosen_points)\n",
        "\n",
        "\n",
        "def euclidean_dist(a, b):\n",
        "  return np.linalg.norm(a-b)\n",
        "\n",
        "\n",
        "def autocovariance(state_traj, ignore_n_first=0, max_lag=50):\n",
        "  T, B, D = state_traj.shape\n",
        "  autocov = list()\n",
        "  for b in range(B):\n",
        "    traj = state_traj[:, b, :]\n",
        "    mean = np.mean(traj, axis=0)\n",
        "    ctraj = traj - mean[np.newaxis, ...]\n",
        "    var = np.var(ctraj, axis=0)\n",
        "    covar = np.matmul(ctraj, ctraj.T)\n",
        "    traj_autocov = np.asarray([np.mean([covar[i, i+l] for i in range(ignore_n_first, T-l)]) for l in range(max_lag)])\n",
        "    autocov.append(traj_autocov)\n",
        "  return np.asarray(autocov)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAW45gklGIlE"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cn35yAj1ADTY"
      },
      "outputs": [],
      "source": [
        "# Download parameters, inputs, and hd cell stats.\n",
        "\n",
        "dataset.download_figure3_files()\n",
        "parameters = dataset.load_figure_3_parameters()\n",
        "visual_inputs = dataset.load_figure_3_visual_inputs()\n",
        "hd_stats = dataset.load_figure_3_hd_stats()\n",
        "\n",
        "p_w = parameters[\"integrator/multi_integrator_nets/prediction_rnn_0/w_gates\"]\n",
        "p_b = parameters[\"integrator/multi_integrator_nets/prediction_rnn_0/b_gates\"]\n",
        "c_w = parameters[\"integrator/multi_integrator_nets/correction_rnn_0/w_gates\"]\n",
        "c_b = parameters[\"integrator/multi_integrator_nets/correction_rnn_0/b_gates\"]\n",
        "step_of_prediction = lambda state, inputs: step_of_lstm(state, inputs, p_w, p_b)\n",
        "step_of_correction = lambda state, inputs: step_of_lstm(state, inputs, c_w, c_b)\n",
        "\n",
        "rnn_initial_states = parameters[\"integrator/memory_map_0/column_context_3_written\"]\n",
        "\n",
        "correction_code = get_visual_correction_codes(parameters, visual_inputs[\"embeddings\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veuObOlN1kFf"
      },
      "outputs": [],
      "source": [
        "# Select hd cells, sorted by preferred angle.\n",
        "\n",
        "hd_cutoff = 0.56\n",
        "n_units = len(hd_stats[\"rnn0_rv_angles\"])\n",
        "hd_ordering = np.argsort(hd_stats[\"rnn0_rv_angles\"])\n",
        "hd_ordering = hd_ordering[hd_stats[\"rnn0_rv_lengths\"][hd_ordering] \u003e hd_cutoff]\n",
        "n_hd_cells = len(hd_ordering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgLpQLXf1kzJ"
      },
      "source": [
        "### Dynamics without corrections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93TVibk09ZxU"
      },
      "outputs": [],
      "source": [
        "# Trajectory with piecewise-constant velocities.\n",
        "\n",
        "T = 1000\n",
        "ang_vel = np.pi / 20\n",
        "n_inputs = 2\n",
        "\n",
        "# Take a valid initial state\n",
        "initial_state_index = 8  # Select a state where the angle starts at 0\n",
        "initial_state = rnn_initial_states[initial_state_index]\n",
        "state = (initial_state, initial_state)\n",
        "\n",
        "# Construct velocity inputs\n",
        "vel = [ang_vel] * (T // 4) + [0] * (T // 4) + [-ang_vel/2.0] * (T // 2)\n",
        "vel = np.asarray([[np.cos(v), np.sin(v)] for v in vel])\n",
        "\n",
        "# Ground-truth integrated velocities\n",
        "true_angular_offset = np.cumsum(np.arctan2(vel[:-1, 1], vel[:-1, 0]))\n",
        "\n",
        "# The network receives the inputs scaled by 10 (to increase the range)\n",
        "vel = vel * 10\n",
        "trajectory = []\n",
        "for i in range(T):\n",
        "  output, state = step_of_prediction(state, vel[i])\n",
        "  trajectory.append(output)\n",
        "trajectory = np.asarray(trajectory)\n",
        "demo_trajectory = trajectory[:, hd_ordering]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClvZPdp0YJvp"
      },
      "outputs": [],
      "source": [
        "# Calculate PCA space.\n",
        "\n",
        "# Remove repeated points\n",
        "pca_from = take_if_farther_than(trajectory, euclidean_dist, 0.1)[1]\n",
        "pca_from = np.asarray(pca_from)\n",
        "cov_mat = np.cov(pca_from.T)\n",
        "cov_mat += np.eye(cov_mat.shape[0]) * 1e-4\n",
        "\n",
        "# Covariance matrix of all units with 16 times the variance for random inits\n",
        "diag_cov_mat = cov_mat * np.eye(cov_mat.shape[0]) * 16\n",
        "# Distribution of random initialisations\n",
        "initial_dist = scipy.stats.multivariate_normal(mean=np.mean(pca_from, axis=0),\n",
        "                                               cov=diag_cov_mat)\n",
        "\n",
        "# PCA\n",
        "cov = np.cov(pca_from[:, hd_ordering].T)\n",
        "mean = np.mean(pca_from[:, hd_ordering].T, axis=1)\n",
        "eiglambda, eigvec = np.linalg.eig(cov)\n",
        "def project_on_pca(x):\n",
        "  return np.matmul(x - mean, eigvec[:, :2]).real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD3mr9zx2Jn9"
      },
      "outputs": [],
      "source": [
        "#Â Trajectories with zero velocity, from different random initialisations.\n",
        "\n",
        "T = 2000\n",
        "B = 100\n",
        "ang_vel = 0.0\n",
        "vel = np.asarray([[np.cos(ang_vel), np.sin(ang_vel)]] * B)\n",
        "vel = vel * 10\n",
        "\n",
        "trajectories = list()\n",
        "for k in range(1000 // B):\n",
        "  print(\".\", end=\"\")\n",
        "  state = initial_dist.rvs(B)\n",
        "  out_traj = [state]\n",
        "  state = (state, state)\n",
        "  for _ in range(T):\n",
        "    output, state = step_of_prediction(state, vel)\n",
        "    out_traj.append(output)\n",
        "  trajectories.append(np.rollaxis(np.asarray(out_traj), 1))\n",
        "\n",
        "trajectories = np.concatenate(trajectories)\n",
        "trajectories_ordered = trajectories[:, :, hd_ordering]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avzBxSZCImnJ"
      },
      "outputs": [],
      "source": [
        "# Find attractor states\n",
        "\n",
        "all_pca = project_on_pca(trajectories_ordered[:, 3:, :])\n",
        "minpca, maxpca = np.amin(all_pca, axis=(0, 1)), np.amax(all_pca, axis=(0, 1))\n",
        "pca_range = maxpca - minpca\n",
        "pcalims = np.stack([np.abs(minpca - 0.1 * pca_range), np.abs(maxpca + 0.1 * pca_range)]).max(axis=0)\n",
        "xlim_pca = [-pcalims[0], pcalims[0]]\n",
        "ylim_pca = [-pcalims[1], pcalims[1]]\n",
        "chosen = list()\n",
        "pca = project_on_pca(trajectories_ordered[:, -1, :])\n",
        "converged_angles_on_pca = np.arctan2(pca[:, 1], pca[:, 0])\n",
        "for i, ang in zip(converged_angles_on_pca.argsort(), converged_angles_on_pca[converged_angles_on_pca.argsort()]):\n",
        "  if not chosen:\n",
        "    chosen.append(i)\n",
        "    last_ang_added = ang\n",
        "  elif (ang - last_ang_added) \u003e 0.1*np.pi/360 * 2:\n",
        "    chosen.append(i)\n",
        "    last_ang_added = ang\n",
        "\n",
        "attractor_states = trajectories[chosen, -1, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEQle0Y0zuda"
      },
      "source": [
        "### Dynamics with visual corrections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "611a4znQtWfm"
      },
      "outputs": [],
      "source": [
        "# Run the correction + dynamics for T steps from the attractor states\n",
        "\n",
        "T = 200\n",
        "B = attractor_states.shape[0]\n",
        "I = 512  # Different image corrections\n",
        "\n",
        "ang_vel = 0.0\n",
        "vel_inputs = np.asarray([np.cos(ang_vel), np.sin(ang_vel)]) * 10.0\n",
        "vel_inputs = np.tile(vel_inputs[np.newaxis, :], (B, 1))\n",
        "\n",
        "traj_pca_points = list()\n",
        "\n",
        "for i in range(I):\n",
        "  rnn_state = attractor_states\n",
        "  correction_code_batch = np.tile(correction_code[[i], :], (B, 1))\n",
        "  image = visual_inputs[\"images\"][i]\n",
        "\n",
        "  state_traj = list()\n",
        "  state_traj.append(rnn_state)\n",
        "  rnn_state = (rnn_state, rnn_state)\n",
        "  for t in range(T):\n",
        "    out, rnn_state = step_of_correction(rnn_state, correction_code_batch)\n",
        "    out, rnn_state = step_of_prediction(rnn_state, vel_inputs)\n",
        "    state_traj.append(out)\n",
        "  state_traj = np.asarray(state_traj)\n",
        "\n",
        "  pc = project_on_pca(state_traj[:, :, hd_ordering])\n",
        "  traj_pca_points.append(pc)\n",
        "\n",
        "traj_pca_points = np.asarray(traj_pca_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwdG65r2uyVr"
      },
      "outputs": [],
      "source": [
        "# Time to convergence\n",
        "\n",
        "time_to_single_attractor = np.asarray([np.inf] * traj_pca_points.shape[0])\n",
        "for i in range(traj_pca_points.shape[0]):\n",
        "  for t in range(traj_pca_points.shape[1]):\n",
        "    att_inds, att_points = take_if_farther_than(traj_pca_points[i, t],\n",
        "                                                euclidean_dist,\n",
        "                                                0.1)\n",
        "    if len(att_inds) == 1:\n",
        "      time_to_single_attractor[i] = t\n",
        "      break\n",
        "\n",
        "examples_in_bin_1 = np.where(np.logical_and(time_to_single_attractor \u003e 0,\n",
        "                                            time_to_single_attractor \u003c 10))[0]\n",
        "examples_in_bin_final = np.where(time_to_single_attractor \u003e 200)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK0JVnty4hIp"
      },
      "source": [
        "### Plot figure 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVxMzRfG1u9L"
      },
      "outputs": [],
      "source": [
        "figsize_y = 5.05\n",
        "fig = plot_utils.SuperFigure(6.2, figsize_y, dpi=180)\n",
        "\n",
        "simulation_panel_coords = [0.45, 0.6, 4.1, 0.5]\n",
        "groundtruth_simulation_panel_coords = [0.45, 0.2, 4.1, 0.3]\n",
        "pca_panel_coords = [5.1, 0.2, 1.0, 1.0]\n",
        "delta_panel_coords = [0.3, 1.6, 1.0, 1.0]\n",
        "pca_random_panel_coords = [1.9, 1.6, 1.0, 1.0]\n",
        "pca_attractor_panel_coords = [3.5, 1.6, 1.0, 1.0]\n",
        "autocorr_panel_coords = [5.1, 1.6, 1.0, 1.0]\n",
        "ttc_panel_coords = [0.3, 3.4, 2.0, 1.2]\n",
        "\n",
        "# Panel A. Simulation of integration of velocities\n",
        "ax = fig.add_subplots_to_figure(1, 1, *simulation_panel_coords,\n",
        "                                text=None, text_offset=-0.15)[0, 0]\n",
        "ax.matshow(demo_trajectory.T, cmap=\"coolwarm\", aspect=3.5)\n",
        "ax.grid(\"off\")\n",
        "ax.set_yticks(np.arange(0, n_hd_cells+1, 10))\n",
        "ax.set_ylabel(\"Unit\")\n",
        "ax.set_xticks(np.arange(0, 1000+1, 100))\n",
        "ax.xaxis.tick_bottom()\n",
        "ax.set_xlabel(\"Integration steps\")\n",
        "plot_utils.setup_spines(ax)\n",
        "\n",
        "# Panel A. Ground truth angular offset\n",
        "unit0_angular_offset = -np.pi\n",
        "display_angular_offset = np.arctan2(np.sin(true_angular_offset + unit0_angular_offset),\n",
        "                                    np.cos(true_angular_offset + unit0_angular_offset))\n",
        "\n",
        "ax = fig.add_subplots_to_figure(1, 1, *groundtruth_simulation_panel_coords,\n",
        "                                hspace=0.3, text=\"A)\", text_offset=-0.3)[0, 0]\n",
        "ax.plot(display_angular_offset, \".\")\n",
        "ax.set_xticks(np.arange(0, 1000+1, 100))\n",
        "ax.set_xlim(0, 1000)\n",
        "ax.set_ylim(-np.pi, np.pi)\n",
        "ax.set_yticks([-np.pi, 0., np.pi])\n",
        "ax.set_yticklabels([r\"$-\\pi$\", r\"$0$\", r\"$\\pi$\"])\n",
        "\n",
        "ax.set_xticks(np.arange(0, 1000+1, 100))\n",
        "ax.set_xticklabels([])\n",
        "ax.xaxis.tick_bottom()\n",
        "ax.set_ylabel(\"True angle\")\n",
        "plot_utils.setup_spines(ax)\n",
        "\n",
        "# Panel B. PCA of simulation\n",
        "ax = fig.add_subplots_to_figure(1, 1, *pca_panel_coords,\n",
        "                                text=\"B)\", text_offset=-0.15)[0, 0]\n",
        "pca_values = project_on_pca(demo_trajectory)\n",
        "ax.scatter(pca_values[:, 0], pca_values[:, 1], alpha=0.1, color=\"grey\")\n",
        "ax.set_xlabel(\"PC 1\")\n",
        "ax.set_ylabel(\"PC 2\")\n",
        "ax.set_xlim(xlim_pca)\n",
        "ax.set_ylim(ylim_pca)\n",
        "plot_utils.setup_spines(ax)\n",
        "\n",
        "\n",
        "# Panel C. Norm change in state vs time\n",
        "ax = fig.add_subplots_to_figure(1, 1, *delta_panel_coords,\n",
        "                                text=\"C)\", text_offset=-0.15)[0, 0]\n",
        "delta = np.linalg.norm(trajectories_ordered[:, :-1, :] - trajectories_ordered[:, 1:, :], axis=-1)\n",
        "plt.plot(np.quantile(delta, .95, axis=0)[:100], linewidth=1, color=\"b\")\n",
        "plt.plot(np.quantile(delta, .05, axis=0)[:100], linewidth=1, color=\"b\")\n",
        "plt.plot(delta.mean(axis=0)[:100], linewidth=2, color=\"b\")\n",
        "ax.set_xlim(0, 100)\n",
        "ax.set_ylim(0, 2)\n",
        "ax.set_xlabel(\"Steps of dynamics\")\n",
        "ax.set_ylabel(\"Change in activations\")\n",
        "plot_utils.setup_spines(ax)\n",
        "\n",
        "# Panel D. PCA of simulations from random initialisations\n",
        "ax = fig.add_subplots_to_figure(1, 1, *pca_random_panel_coords,\n",
        "                                text=\"D)\", text_offset=-0.15)[0, 0]\n",
        "initializations = trajectories_ordered[:, 0, :]\n",
        "pca_values = project_on_pca(initializations)\n",
        "plt.scatter(pca_values[:, 0], pca_values[:, 1], alpha=0.1, color=\"grey\")\n",
        "\n",
        "not_yet_converged_states = trajectories_ordered[:, 10, :]\n",
        "pca_values = project_on_pca(not_yet_converged_states)\n",
        "plt.scatter(pca_values[:, 0], pca_values[:, 1], alpha=0.1, color=\"green\")\n",
        "\n",
        "converged_states = trajectories_ordered[:, -1, :]\n",
        "pca_values = project_on_pca(converged_states)\n",
        "plt.scatter(pca_values[:, 0], pca_values[:, 1], alpha=1.0, color=\"k\", marker=\"x\")\n",
        "\n",
        "ax.set_xlabel(\"PC 1\")\n",
        "ax.set_ylabel(\"PC 2\")\n",
        "ax.set_xlim(xlim_pca)\n",
        "ax.set_ylim(ylim_pca)\n",
        "plot_utils.setup_spines(ax)\n",
        "\n",
        "# Panel E. PCA CW and CCW cyclic attractor\n",
        "init = 0\n",
        "ax = fig.add_subplots_to_figure(1, 1, *pca_attractor_panel_coords,\n",
        "                                text=\"E)\", text_offset=-0.15)[0, 0]\n",
        "for (i, ang_vel, col, label) in zip([11, 41], [-0.16, 0.16], [\"r\", \"b\"],\n",
        "                                    [r\"$\\omega=\\frac{\\pi}{20}$\", r\"$\\omega=-\\frac{\\pi}{20}$\"]):\n",
        "  vel_state_traj = unroll_rnn_with_fixed_vel(trajectories[i, [0], :], ang_vel, 50, step_of_prediction)\n",
        "  pca_values = project_on_pca(vel_state_traj[:, :, hd_ordering])\n",
        "  vels = pca_values[1:, :, :] - pca_values[:-1, :, :]\n",
        "  alpha = 0.5\n",
        "  for b in range(vel_state_traj.shape[1]):\n",
        "    plt.scatter(pca_values[0, b, 0], pca_values[0, b, 1], alpha=1.0, color=col)\n",
        "    ax.quiver(pca_values[init:-1, b, 0], pca_values[init:-1, b, 1], vels[init:, b, 0], vels[init:, b, 1],\n",
        "              scale_units=\"xy\", scale=1.0, color=col, alpha=alpha, width=0.005, headwidth=8, label=label)\n",
        "\n",
        "ax.legend(loc=\"lower right\")\n",
        "ax.set_xlabel(\"PC 1\")\n",
        "ax.set_ylabel(\"PC 2\")\n",
        "ax.set_xlim(xlim_pca)\n",
        "ax.set_ylim(ylim_pca)\n",
        "plot_utils.setup_spines(ax)\n",
        "\n",
        "# Panel F. Autocorrelation plot\n",
        "ax = fig.add_subplots_to_figure(1, 1, *autocorr_panel_coords,\n",
        "                                text=\"F)\", text_offset=-0.15)[0, 0]\n",
        "\n",
        "for ang_vel, col, label in zip([-0.16, 0.16], [\"r\", \"b\"], [r\"$\\omega=\\frac{\\pi}{20}$\", r\"$\\omega=-\\frac{\\pi}{20}$\"]):\n",
        "  state_traj = unroll_rnn_with_fixed_vel(trajectories[:, 0, :], ang_vel, 200, step_of_prediction)\n",
        "  autocovs = autocovariance(state_traj)\n",
        "  ax.plot(autocovs.mean(axis=0)[:100], linewidth=1, color=col, label=label)\n",
        "\n",
        "ax.set_xlabel(\"Steps of dynamics\")\n",
        "ax.set_ylabel(\"Autocovariance\")\n",
        "ax.legend(loc=\"lower right\")\n",
        "plot_utils.setup_spines(ax)\n",
        "\n",
        "# Panel G. Time to convergence to a single attractor point while correctiong visually\n",
        "T = 200\n",
        "ax = fig.add_subplots_to_figure(1, 1, *ttc_panel_coords)[0, 0]\n",
        "fig.add_text(ttc_panel_coords[0]-0.15, ttc_panel_coords[1]-0.30, text=\"G)\")\n",
        "\n",
        "nbins = 20\n",
        "ax.hist(time_to_single_attractor, bins=np.linspace(0, T, nbins))\n",
        "ax.bar(T, np.sum(np.isinf(time_to_single_attractor)), width=T/nbins, color=\"r\", align=\"edge\")\n",
        "ax.set_xlim(0, 210)\n",
        "ax.set_xticks([0, 50, 100, 150, 200])\n",
        "ax.set_xticklabels([\"0\", \"50\", \"100\", \"150\", \"  \u003e200\"])\n",
        "\n",
        "# Plot the quick-convergence visual image examples\n",
        "im_width = 40\n",
        "for column, image_id in enumerate(examples_in_bin_1[:3]):\n",
        "  im = OffsetImage(visual_inputs[\"images\"][image_id], zoom=0.8)\n",
        "  im.image.axes = ax\n",
        "  xy = (5, 250)\n",
        "  xybox = (50 + im_width * column, 250)\n",
        "  if column == 0:\n",
        "    arrowprops = dict(arrowstyle=\"-\u003e\", color=\"k\")\n",
        "  else:\n",
        "    arrowprops = None\n",
        "  ab = AnnotationBbox(im, xy,\n",
        "                      xybox=xybox,\n",
        "                      xycoords=\"data\",\n",
        "                      boxcoords=\"data\",\n",
        "                      box_alignment=(0.5, 0.5),\n",
        "                      pad=0.1,\n",
        "                      bboxprops=dict(color=\"#4C72B0\"),\n",
        "                      arrowprops=arrowprops)\n",
        "  ax.add_artist(ab)\n",
        "\n",
        "# Plot the non-convergent visual image examples\n",
        "for column, image_id in enumerate(examples_in_bin_final[:3]):\n",
        "  im = OffsetImage(visual_inputs[\"images\"][image_id], zoom=0.8)\n",
        "  im.image.axes = ax\n",
        "  xy = (205, 100)\n",
        "  xybox = (150 - im_width * column, 100)\n",
        "  if column == 0:\n",
        "    arrowprops = dict(arrowstyle=\"-\u003e\", color=\"k\")\n",
        "  else:\n",
        "    arrowprops = None\n",
        "  ab = AnnotationBbox(im, xy,\n",
        "                      xybox=xybox,\n",
        "                      xycoords=\"data\",\n",
        "                      boxcoords=\"data\",\n",
        "                      box_alignment=(0.5, 0.5),\n",
        "                      pad=0.1,\n",
        "                      bboxprops=dict(color=\"r\"),\n",
        "                      arrowprops=arrowprops)\n",
        "  ax.add_artist(ab)\n",
        "\n",
        "plot_utils.setup_spines(ax)\n",
        "ax.set_xlabel(\"Time to convergence\")\n",
        "ax.set_ylabel(\"Proportion of images\")\n",
        "ax.set_ylim(0, 384)\n",
        "ax.set_yticks([0, 128, 256, 384])\n",
        "ax.set_yticklabels([0.0, 0.25, 0.5, 0.75])\n",
        "\n",
        "# Panels H and I. State trajectories (in PC-space) correcting with 3 particular images\n",
        "# Different colours show different initial rnn states\n",
        "colors = get_cmap(\"tab20b\").colors\n",
        "best_examples = np.concatenate((examples_in_bin_1[:2], examples_in_bin_final[:1]))\n",
        "for ex_i, (ex, label) in enumerate(zip(best_examples, [\"H)\", \"\", \"I)\", \"\"])):\n",
        "  corr_att1_x = 2.7 + ex_i * 1.2\n",
        "  ax = fig.add_subplots_to_figure(1, 1,\n",
        "                                  corr_att1_x + 0.20, ttc_panel_coords[1]-0.4, 0.5, 0.5,\n",
        "                                  text=label, text_offset=[-0.35, 0.1])[0, 0]\n",
        "  ax.imshow(visual_inputs[\"images\"][ex])\n",
        "  ax.set_axis_off()\n",
        "  plot_utils.setup_spines(ax)\n",
        "\n",
        "  ax = fig.add_subplots_to_figure(1, 1,\n",
        "                                  corr_att1_x, ttc_panel_coords[1] + 0.3, 0.9, 0.9,\n",
        "                                  text=\"\", text_offset=-0.15)[0, 0]\n",
        "  B = attractor_states.shape[0]\n",
        "  rnn_state = attractor_states\n",
        "  correction_code_batch = np.tile(correction_code[[ex], :], (B, 1))\n",
        "\n",
        "  state_traj = list()\n",
        "  state_traj.append(rnn_state)\n",
        "  rnn_state = (rnn_state, rnn_state)\n",
        "  for t in range(T):\n",
        "    if t % 1 == 0:\n",
        "      out, rnn_state = step_of_correction(rnn_state, correction_code_batch)\n",
        "    out, rnn_state = step_of_prediction(rnn_state, vel_inputs)\n",
        "    state_traj.append(out)\n",
        "  state_traj = np.asarray(state_traj)\n",
        "\n",
        "  pc = project_on_pca(state_traj[:, :, hd_ordering])\n",
        "  vels = pc[1:, :, :] - pc[:-1, :, :]\n",
        "\n",
        "  for b in range(B):\n",
        "    col = colors[b % len(colors)]\n",
        "    plt.scatter(pc[0, b, 0], pc[0, b, 1], alpha=1.0, color=col)\n",
        "    ax.quiver(pc[:-1, b, 0], pc[:-1, b, 1], vels[:, b, 0], vels[:, b, 1],\n",
        "              scale_units=\"xy\", scale=1.0, color=col, width=0.005, headwidth=8)\n",
        "    plt.scatter(pc[-1, b, 0], pc[-1, b, 1], alpha=1.0, color=\"k\", marker=\"x\")\n",
        "\n",
        "  ax.set_xlabel(\"PC 1\")\n",
        "  if ex_i == 0:\n",
        "    ax.set_ylabel(\"PC 2\")\n",
        "  ax.set_xlim(xlim_pca)\n",
        "  ax.set_ylim(ylim_pca)\n",
        "  ax.set_aspect(1.0)\n",
        "  plot_utils.setup_spines(ax)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "figure_3.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
